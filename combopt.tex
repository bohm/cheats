\input cheatmac
\usepackage[czech]{babel}
\begin{document}
\begin{multicols}{3}

\def\alg{ALG}
\def\vcorr{\vskip -2.5em}
\title{Combinatorial optimization}

\fsection{Graph algorithms}

\subsection{Union-find}

Creating and updating an equivalence. Operations UNION (union of two classes)
and FIND (detect equivalence class). FIND actually outputs a canonical
representative.

Tarjan's UF employs:

\begin{itemize}
\item Path compression -- compress any path that you go through by linking it at a root.
\item Union by rank -- every representative remembers its $r(v)$ (rank). When doing UNION,
declare higher ranking vertex as representative. If ranks equal, increase rank.
\end{itemize}

\thm{With $n$ elements, $m$ operations UNION/FIND take $O( (n+m) \log^{*} n)$.}

\prf{ Create buckets of vertices based on their rank. In the bucket $k$ there
are vertices of rank $((2↑k-1),2↑k]$.

\obs{In $k$-th bucket, there are at most $n/(2↑k)$ vertices}
\prf[Obs.]{There are at most $n/2^r$ vertices of rank $r$, because of how rank
merges trees. Apply this result to the buckets.}

%TODO: Maybe a more verbose explanation after finals.

Now, do the accounting.

}

% \subsection{Nagamochi-Ibaraki}

\subsection{Minimum spanning tree}

Minimum is counted based on the weight function. We say a tree is
lighter if $T$ is better than another $T'$.

\dfn{Light edges $≡$ we can swap them in a $T$ to get a lighter spanning tree.}

\obs{We can arrive at any minimum spanning tree from any tree using swap operations.}

\dfn{Blue edge $≡$ lightest edge of some edge cut.}

\dfn{Red edge $≡$ heaviest edge on a cycle.}

Meta-algorithm: try to avoid red edges while gathering blue edges.

\alg{Jarnik's algorithm with a Fib. heap}
\begin{itemize}
\item Put all elements in a heap.
\item Extract minimum edge $uv$ $(u ∈ T, v ∉ T)$, add to $T$.
\item For all neighbours $w$ of $v$ which aren't in $T$:
\item If edge $wv$ is lighter than any edge to $w$ in heap, add it.
\item DECREASKEY the edge that is heavier than $wv$, if you added it.
\end{itemize}

Complexity: $O(m + n log n)$.

Note: oftentimes we can use Courcelle's Theorem to get fast algorithms
on hard problems, if our structure is bounded by treewidth or other parameter.

%TODO: Planar separator?

\fsection{Algebraic and arithmetic algorithms}

\subsection{Strassen}

\subsection{Euclid's Algorithm}

\subsection{RSA}

\subsection{Working with $Q^n$}

\fsection{Polytope theory}

\dfn{{\it Polyhedron:} $P = \{x ∈ R^n | Ax ≤ b \}$.}

\dfn{{\it Convex set:} $∀x,y λ_1 x + λ_2 y ∈ C$.}

\dfn{{\it Convex hull:}}

Basic property of convex sets: if an element is outside, it can be separated by a hyperplane,
but an element on the inside cannot.

\dfn{{\it Halfspace:} $\{x | c^Tx ≤ δ \}$.}

\dfn{{\it Polytope:} Convex hull of a finite set of vertices.}

\dfn{{\it Vertex:} A point in a polytope/polyhedron which isn't a convex combination of any two points.}

\dfn{{\it Simplex:} Convex hull of an affinely independent set of vertices.}

\dfn{{\it Geometric duality:} To a point $a ≠ 0$ in $R^d$ we assign the hyperplane $h = \{x| ax = 1\}$ and
to a hyperplane not passing through the origin we do the same, assign to it the point $a$.}


\dfn{$A_z ≡$ the set of vectors of $A$ satisfying $a_i z = b_i$}.

\thm{$v$ vertex of $P ⇔ r(A_v) = n$}

\prf{$⇒$: $A_z$ not full rank $→$ find $c: A_z c = 0$.
$v$ is then a conv. combination of $v+δc, v - δc$ for some $δ >0$.

$⇐$: $v$ not a vertex $→$ find two elements which combine to it;
$A_v(x-y) = 0$. 
}

\thm{A bounded polyhedron with $t$ vertices $⇔ P=conv(x_1, …, x_t)$.}

\prf{First implication $P = ⋂Γ$. Hyperplanes are of dimension $d-1$,
apply induction. Get set of vertices $V_i$ for each hyperplane.
$∪V$ is then the set of vertices of $P$. If there is a $x ∈ P$, it is
on a line, and this line is bounded by at least two hyperplanes, but the
elements on the hyperplanes can be expressed as a convex combination, as
so $x$ is a conv. combination also.

Second implication by duality.
}

\obs{Cyclic polytopes have $n$ vertices and roughly ${n - d/2 \choose d/2}$
facets. Cyclic polytopes also maximize the number of faces in each dimension for
$n$.}

\dfn{{\it Projection} of $x$ onto a a closed, convex, nonempty set $K$ is a
 point $p ∈ K$ that minimizes distance $||p - x||$.}
 
\thm[Projection theorem]{$K$ closed, convex, nonempty in $R^n$, $p(x)$ projection of $x$.
Then $∀z ∈ K$, $(z-p)^T(b-p) ≤ 0$.}

\fsection{LP}

The standard LP setting (everything without indices are vectors):
\[ \min c^Tx, \]
\vcorr
\[ Ax = b, \]
\vcorr
\[ x ≥ 0, \]

We can always move to inequalities, change min to max, as long as we stay linear.

\thm[Farkas Lemma]{Exactly one is true:
\begin{itemize}
\item $∃x≥0: Ax=b$
\item $∃y: A^Ty ≥ 0, b^Ty < 0$.
\end{itemize}
}

\prf{

Not two at the same time:
\[ Ax = b → 0 ≤ x^T A^Ty = y^TAx = y^Tb < 0. \]

($¬1 → 2$): Assume no $Ax=b$. Look at cone $K = \{Ax| x≥0\}$. $b ∉ K$.
Project $b$ onto $K$, get $p$. Use Projection Theorem: $∀z ∈ K, (z-p)^T(b-p) ≤ 0$.
Define $y ≡ p - b$. $∀x: (Ax-p)^T(y) ≥ 0$ (inequality switches due to $y$). $p = Aw$ in cone,
so $∀x: (Ax - Aw)^T(y) = (x-w)^T (A^Ty) ≤ 0$. Choose $x = w + (0,0,0,…,1,…,0)$. This extracts
one column of $A$. $x≥0$, because $w ≥ 0$. So $(A^Ty) ≥ 0$.

$y^Tb = (p-y)^T y = p^Ty - y^Ty.$ Again, $(Ax -p)^Ty ≥ 0$, so $p^Ty ≤ 0$ for $x ≡ 0$. However,
$p^Ty ≠ 0$. 
}

\cor{Exactly one is true:
\begin{itemize}
\item $∃x≥0: Ax ≤ b$,
\item $∃y≥0: A^Ty = 0, b^Ty <0$.
\end{itemize}
}

\subsection{Duality}

Assume minimazation. We are trying to get a lower bound on the $c^Tx$. We can do this
if we find a vector $y$ such that $y^T Ax = b^Ty$, and we try to make it happen so that
$y^TA$ (coefficents of $x$) are below $c^T$. Therefore, we have a dual program:

\[ \max b^Ty\]
\vcorr
\[ A^Ty ≤ c\]

\thm[Weak duality]{Solution of dual $w ≤ z ≡$ solution of primal.}

\prf{Directly from argument above.}

\thm[Strong duality]{$w = z$.}

\prf{
Suppose primal bounded (and feasible), $x*$ optimum. We now look for $y$ s.t. $A^Ty ≤ c$ and
$b^Ty ≥ z = c^Tx*$. Suppose there is none, then (applying Farkas corollary on
modified matrices) there is $x ≥ 0, λ ≥ 0$ such that
\[Ax = λb,\]
\vcorr
\[c^Tx < λz.\]

If $λ ≠ 0$, we can normalize it to be $λ = 1$ and we have improvement over an
optimum. If $λ = 0$, we can go to $-∞$ with cost.
}

\fsection{Integrality and ILP}

Incidence matrix $≡$ $V × E$.

\dfn{A matrix $M$ is totally unimodular $≡$ every square submatrix has determinant -1,0 or 1.}

\thm{Suppose $A$ is totally unimodular, then each vertex of the polyhedron $\{x|Ax ≤ b\}$ is integral.}

\prf{Vertex $z$. Use observation that $A_z = \{col(A)| z_j ≠ 0\}$  has full rank. Therefore it is invertible.
Since $|det A'| = 1$, all entries of the inverse are integer.}

\thm[Hoffman-Kruskal]{$A$ is unimodular $⇔$ $∀ b$ integer vector the polyhedron
$Ax ≤ b, x ≥ 0$ is integer.
}

\thm{$G$ bipartite $⇔$ incidence matrix $A$ is totally unimodular.}

\prf{$G$ not bipartite $→$ take submatrix of odd cycle, calculate
determinant.

$G$ bipartite. Take $t×t$ matrix $M$, proceed by induction. if $M$
has a column of zeroes or with just one $1$, all done. If each column
has two $1$s, split the matrix based on the partitions.}


\fsection{Simplex method}

We work with a normalized problem, i.e.:
\[ \min c_B x_B + c_N x_N \]
\vcorr
\[ s.t. A_B x_B + A_N x_N = b, x_B, x_N ≥ 0.\]

Idea: in a minimization problem, we can look at the solution we're in
as a base $x_B$ (full vertices) plus additional vectors that sum us up
to $b$. We check if one $x_N$ can decrease the cost function. If so,
increase contribution of $x_N$ while satisfying equality.

Make sure that $x_B ≥ 0$ until it breaks, then we basically
added a new vector to the base $B$. 

Note: Many heuristics for pivot choice. Also we need to make sure that
removing an element of the basis $k$ which doesn't create a loop in
the next step.  (The loop may happen if one element is already set to
$0$ in the basis.) Pivoting rule that works: choose $k,j$ minimal.

\opn[Hirsch]{For $m$ hyperplanes in $d$ dimensions the length of the
shortest path between any two vertices of the arrangement is at most
$m-d$.}

Not even a proof of the Hirsch conjecture would say much about the Simplex
algorithm. Existence of polynomial scheme is still open.

\fsection{Ellipsoid method}

Our problem is a modified problem: we want to find for a given polytope
$Ax \leq b$ a solution or answer that it's empty.

\dfn{A symmetric matrix $A ∈ R^{n+n}$ is positive definite, if $∀ x ≠ 0: x^T A x > 0$.}

\thm{TFAE:
\begin{itemize}
\item All eigenvalues are positive,
\item Inversion matrix $A^{-1}$ is also positive defiinite,
\item $∃ U: U^TU = A$. $U$ will be denoted as $A^{1/2}$.
\end{itemize}
}

\dfn{A set $\{x| (x-a)^T A^{-1} (x-a) ≤ 1\}$ is called an {\it ellipsoid} with center $a$
and defined by the (by the definition positive definite) matrix $A$.}

\dfn{Affine map: $T = Qx + s$.} 

\obs{An ellipsoid is an affine map of $E(0,I)$.}

\prf{Translate it by $A^{1/2}$ and $a$.}

\thm{For affine maps, $vol(T(X)) = |\det Q| vol(X)$.}

\obs{for $vol(E(a,A))$ holds that $|det A^{1/2}|n^{-n} ≤ vol(E(a,A)) ≤ |det A^{1/2}| 2^{n}$.}

\obs{If we can answer the existence of an element in polynomial time, we can calculate
LP in polynomial time.}

\prf{Create a polytope in $R^{m+n}$ which encapsulates both the primal and the 
dual conditions. If an element exists, it necessarily is an optimum.}

\subsection{Finding initial ellipsoid.}
\lem[Hadamard]{$|det C| ≤ ∏ || C_i ||$.}

\lem{$C$ integral. Then $|det C| ≤ 2^{<C> - n^2}$.}


\thm{if $P \equiv \{x | Cx \leq d \} \subseteq Q^{n}$ is a limited polytope and $C,d$ are integral,
then all vertices of $P$ are contained within a ball of origin $(0,0)$ and radius $R = \sqrt{n} 2^{<C,d> + n log n}$.
}

\subsection{Simple iteration step}

\[E_k = E(0,I), H_k = \{x| x_1 \leq 0 \}.\]

Since the broken condition is in the direction of $x_1$, we want to create an ellipsoid of the form
\[E' = \{ (x - te_1)^T Z^{-1} (x - te_1) \leq 1 \}.\]

$Z$ will be diagonal. We want to ``shrink'' along $x_1$. Pick $p < 1, d > 1$ and set
$Z$ diagonal with the diagonal $(1/p^2, 1/d^2, 1/d^2, \dots)$. We want our ellipsoid
to touch points $e_1, e_2$ and be volume-minimal with this property.

First condition gives: $(1+t)^2 / p^2 = 1$.
Second condition gives: $t^2/p^2 + 1/d^2 = 1$.

We know that $vol(E) = \sqrt{|det Z|} vol (B)$. Calculate the volume, you should get
$t = -1/n+1$.

\subsection{Complex iteration step}

Affine transform the ellipsoid to the simple iteration step. You have to do
some rotation for the hyperplane, but it will not matter. Harder calculations.

\subsection{Ending observation}

\obs{If a $P = {Ax \leq b}$ has full rank, then $vol(P) \geq 2^{-(n+1)<C> + n^3}$.}

\prf{Sketch. (Affinely) transform the polytope into $n$ unit vectors and $0$.  Vertices are such
that a subset of columns where $A_x$ have full rank. Use Cramer rule and calculate total volume.
}

\fsection{Special matrices}

Totally unimodular matrix.

Positive semidefinite matrix.

\fsection{TSP}

\bigskip

\bigskip

\fsection{Matching and flow networks}

\subsection{Edmonds}

Edmonds' polytope:

\[ f ∈ R^{E(G)}: ∑_v f(e) ≤ 1\]
\vcorr
\[ ∑_{e∈X} f(e) ≤ |X|-1/2 {\rm\ for\ odd\ }X. \]

Perfect matching polytope has equality in the first condition and
the second condition:

\[ ∑_{e ∈ X} f(e) ≥ 1. \]

{\dfn $r$-graph: Graph that is $r$-regular and all edge cuts of
odd size are at of size at least $r$.}

Example of an $r$-graph: cubic bridgeless graphs.

\thm{Every $r$-graph has a uniform cover by perfect matchings.}

\prf{Every element of the perfect matching polytope is a convex
combination of perfect matchings. set $f(e) = 1/r$ everywhere,
then this $f$ is in the polytope of PMP.}

\res{Every cubic bridgeless graph has a uniform cover by perfect
matchings (and also a perfect matching).}

\res{Every cubic bridgeless graph has a perfect matching such
that it contains no odd cut of size $3$.}

\res{Every cubic bridgeless graph has perfect matchings $M_1$, $M_2$
such that $E(M_1) ∪ E(M_2) ≥ 3E/5$. }

\prf{Take one PM $M$ that contains no odd cut of size $3$. Define $f(e) = 1/5$
on it and $f(e) = 2/5$ elsewhere. Then $f(e)$ is in PMP. Since $f(E ∖ M) = 2/5 |E ∖ M|$,
there is one perfect matching $M_i$ that attains this. Take $M ∪ M_i$ and get $1/3 + 2/3 2/5 = 3/5 E$.
}

Edmonds' algorithm:

Find augmenting paths using an augmenting path BFS tree (Edmonds' tree). If you find an augmenting
path, good. If not, you may find an odd cycle that started as an augmenting path. Contact this cycle,
find augmenting path in the next graph. Proceed until possible.

Total complexity: $O(n^2(n + m))$.

\subsection{Dinitz}

\alg{Dinitz}: Add augmenting flows, not just augmenting paths.
Specifically:

\begin{itemize}
\item Create reserve network. Now we work only with that.
\item Find shortest $s-t$ path by DFS. Cut all longer $s-t$ paths.
\item Find blocking flow on the cleaned network. Whenever adding
a $s-t$ path greedily, clean up the network.
\item Add blocking flow. Iterate.
\end{itemize}

Cleanup takes only $O(m)$ time per iteration, searching for blocking
flow takes $O(nm)$.

\obs{Number of iterations is $O(n)$.}

\prf{The only new edges that get added in the next reserve network are backwards
edges, which only increase the shortest $s-t$ length. Plus (after
cleanup) longer paths may become relevant, but still, shortest $s-t$
path increases before every reserve network construction, and so we
have $O(n)$.}

{\bf Integer capacities}
\obs{On integer capacities, we can bound the running time of Dinitz by $O(|f|n + mn)$.}

\prf{Every augmenting path extends the flow by at least $1$.}

\thm{On integer capacities, we can make Dinitz run in time $O(mn log C)$.}

\prf{We do it similarly to radix sort -- create flows by writing $C$ in binary,
and then finding maximum flow using the first $k$-bits of each capacity. After that,
we multiply the flow by $2$ (and add the smallest bit) and start with a close-enough flow.

\obs{$|f_i| - 2|f_{i-1}| ≤ m$.}

\prf{Max flow = min cut, but min cut has increased from $|R|$ to at most $2|R| + m$.}

Now we use the previous observation on integer Dinitz and flow size to get the result.}

\fsection{Matroid theory}

\end{multicols}
\end{document}